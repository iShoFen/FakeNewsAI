{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Fake News Study* / Etude Fake News\n",
    "\n",
    "*EN* // **FR**\n",
    "\n",
    "*Data files are stored in 'Data' repertory, the whole purpose of this work is to\n",
    "develop an AI that recognizes Fake News, train it and test it to bring it to the highest\n",
    "accuracy possible.*\n",
    "\n",
    "**Les données sont stockées dans le dossier 'Data', le but de ce travail est de développer une IA capable de reconnaître\n",
    "les fake news, l'entraîner, la tester et l'amener à la plus haute précision possible.**\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1639218142362
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utils libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyarrow.feather as ft\n",
    "\n",
    "# AI libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Creating a dataset to work with* / Création du dataset de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1639141056511
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fake = pd.read_csv('../Data/Fake.csv', delimiter=',')\n",
    "true = pd.read_csv('../Data/True.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We now need to merge these two dataframes to be able to use them as one whole entity.\n",
    "Nevertheless, we will need to differentiate real and fake news, so we will have to add\n",
    "an extra column as 'istrue'.*\n",
    "\n",
    "**Nous devons maintenant concaténer ces deux DataFrames pour pouvoir les utiliser en tant qu'une seule et même entité.\n",
    "Cependant, nous devons être capable de différencier les news fakes et réelles, nous allons donc rajouter une colonne\n",
    "de booléens 'istrue'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1639141057023
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fake['istrue'] = 0\n",
    "true['istrue'] = 1\n",
    "\n",
    "data = true.append(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We now have a full dataframe with real and fake news, let's check the dimensions\n",
    "and fields we have.*\n",
    "\n",
    "**Nous avons maintenant un DataFrame complet avec les news réelles et fakes, vérifions dimensions et champs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1639141057115
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  \\\n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n\n                 date  istrue  \n0  December 31, 2017        1  \n1  December 29, 2017        1  \n2  December 31, 2017        1  \n3  December 30, 2017        1  \n4  December 29, 2017        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Analyzing, cleaning and repairing data* / Analyse, nettoyage et réparation des données\n",
    "\n",
    "*Now that we have the dataset we needed, let's look for null or NaN values in it.*\n",
    "\n",
    "**Maintenant que nous avons le bon dataset, regardons s'il contient des valeurs NULL ou NaN.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1639141057206
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "istrue     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can see from this execution that there is no null or NaN value in the dataset, so\n",
    "we won't have to repair any of the data, which is good news.\n",
    "<br>\n",
    "We will now delete the column we won't need during the study : date.*\n",
    "\n",
    "**Nous nous rendons compte suite à cette exécution qu'aucune valeur NULL ou NaN ne se trouve dans le dataset, nous n'aurons donc pas à réparer les données, ce qui est une bonne nouvelle.\n",
    "<br>\n",
    "Nous allons maintenant supprimer la colonne dont nous n'aurons pas besoin dans cette étude : date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1639141057312
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  istrue  \n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews       1  \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews       1  \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews       1  \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews       1  \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*However, we will need to split title contents into more simplified strings to avoid confusion\n",
    "during data processing.\n",
    "<br>\n",
    "To this purpose, we'll use the nltk and re libraries, which contain\n",
    "stopwords and string processing packages (called PortStemmer).\n",
    "But first, let's make an array that contains all titles.*\n",
    "\n",
    "**Cependant, nous allons avoir besoin de séparer les contenus des titres en des chaînes de caractères plus simplifiées pour éviter les confusions durant l'exploitation des données.\n",
    "<br>\n",
    "Pour cela, nous aurons besoin des bibliothèques nltk et re, qui contiennent des packages liés aux mots de liaison et aux traitements de chaînes de caractères (notamment le PortStemmer)**\n",
    "\n",
    "***Stopwords:***\n",
    "<br>\n",
    "*A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search\n",
    "engine has been programmed to ignore, both when indexing entries for searching\n",
    "and when retrieving them as the result of a search query.\n",
    "(https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)*\n",
    "<br>\n",
    "**Un mot de liaison est un mot couramment utilisé (comme \"et\", \"ou\", \"un\", etc) qu'un moteur de recherche a été programmé pour ignorer, que ce soit lors de l'indexation des entrées pour la recherche\n",
    "ou lors de leur récupération en tant que résultat d'une requête de recherche.\n",
    "(https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)**\n",
    "\n",
    "***PortStemmer:***\n",
    "<br>\n",
    "*A PortStemmer is an algorithm used for removing the commoner morphological and\n",
    "inflexional endings from words in English. For example: words such as “Likes”,\n",
    "”liked”, ”likely” and ”liking” will be reduced to “like” after stemming.\n",
    "(https://www.geeksforgeeks.org/python-stemming-words-with-nltk/)*\n",
    "<br>\n",
    "**Un PortStemmer est un algorithme utilisé pour supprimer les terminaisons morphologiques et inflexionnelles les plus courantes des mots.\n",
    "Par exemple, des mots tels que \"Likes\", \"liked\", \"likely\" et \"liking\" seront réduits à \"like\" après le stemming.\n",
    "(https://www.geeksforgeeks.org/python-stemming-words-with-nltk/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1639144263954
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               title  \\\n0  u budget fight loom republican flip fiscal script   \n1  u militari accept transgend recruit monday pen...   \n2       senior u republican senat let mr mueller job   \n3  fbi russia probe help australian diplomat tip nyt   \n4  trump want postal servic charg much amazon shi...   \n\n                                                text       subject  istrue  \n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews       1  \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews       1  \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews       1  \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews       1  \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>u budget fight loom republican flip fiscal script</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>u militari accept transgend recruit monday pen...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>senior u republican senat let mr mueller job</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fbi russia probe help australian diplomat tip nyt</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trump want postal servic charg much amazon shi...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = np.array(data['title'])\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "corpustitle = []\n",
    "\n",
    "for i in range (titles.shape[0]):\n",
    "    new = re.sub('[^a-zA-Z]', ' ', titles[i])\n",
    "    # Replaces any string matching the regex with spaces (anything other than a letter)\n",
    "\n",
    "    new = new.lower()\n",
    "\n",
    "    new = new.split()\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    new = [ps.stem(word) for word in new if not word in set(stopwords.words('english'))]\n",
    "\n",
    "    new = ' '.join(new)\n",
    "\n",
    "    corpustitle.append(new)\n",
    "\n",
    "data['title'] = corpustitle\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1639143840239
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  \\\n0  u budget fight loom republican flip fiscal script   \n1  u militari accept transgend recruit monday pen...   \n2       senior u republican senat let mr mueller job   \n3  fbi russia probe help australian diplomat tip nyt   \n4  trump want postal servic charg much amazon shi...   \n\n                                                text       subject  istrue  \n0  washington reuter head conserv republican fact...  politicsNews       1  \n1  washington reuter transgend peopl allow first ...  politicsNews       1  \n2  washington reuter special counsel investig lin...  politicsNews       1  \n3  washington reuter trump campaign advis georg p...  politicsNews       1  \n4  seattl washington reuter presid donald trump c...  politicsNews       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>u budget fight loom republican flip fiscal script</td>\n      <td>washington reuter head conserv republican fact...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>u militari accept transgend recruit monday pen...</td>\n      <td>washington reuter transgend peopl allow first ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>senior u republican senat let mr mueller job</td>\n      <td>washington reuter special counsel investig lin...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fbi russia probe help australian diplomat tip nyt</td>\n      <td>washington reuter trump campaign advis georg p...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trump want postal servic charg much amazon shi...</td>\n      <td>seattl washington reuter presid donald trump c...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = np.array(data['text'])\n",
    "\n",
    "corpustxt = []\n",
    "\n",
    "for i in range (text.shape[0]):\n",
    "    new = re.sub('[^a-zA-Z]', ' ', text[i])\n",
    "    # Replaces any string matching the regex with spaces (anything other than a letter)\n",
    "\n",
    "    new = new.lower()\n",
    "\n",
    "    new = new.split()\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    new = [ps.stem(word) for word in new if not word in set(stopwords.words('english'))]\n",
    "\n",
    "    new = ' '.join(new)\n",
    "\n",
    "    corpustxt.append(new)\n",
    "\n",
    "data['text'] = corpustxt\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1639144819716
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "feather = data.reset_index()\n",
    "feather.to_feather('../Data/datas.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that our titles are simplified, let's vectorize them using CountVectorizer\n",
    "(provided by sklearn)*\n",
    "<br>\n",
    "**Maintenant que nos titres sont simplifiés, vectorisons-les en utilisant CountVectorizer\n",
    "(fourni par sklearn)**\n",
    "\n",
    "***CountVectorizer:***\n",
    "<br>\n",
    "*CountVectorizer is a tool provided by the scikit-learn library. It is used to transform\n",
    "a given text into a vector on the basis of the frequency (count) of each word that occurs\n",
    "in the entire text.\n",
    "(https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)*\n",
    "<br>\n",
    "**CountVectorizer est un outil fourni par la bibliothèque scikit-learn. Il est utilisé pour transformer\n",
    "un texte donné en un vecteur sur la base de la fréquence (comptage) de chaque mot qui apparaît\n",
    "dans le texte entier.\n",
    "(https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1639218190491
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "countv = CountVectorizer(max_features=5000)\n",
    "data = pd.read_feather('../Data/datas.feather')\n",
    "# max_features: we are selecting the 5000 most used words in the whole dataset\n",
    "\n",
    "X1 = countv.fit_transform(data['title']).toarray().tolist()\n",
    "# Results are being encoded by the 'transform' part of the method\n",
    "\n",
    "data['title'] = X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "countv = CountVectorizer(max_features=5000)\n",
    "\n",
    "# max_features: we are selecting the 5000 most used words in the whole dataset\n",
    "\n",
    "X2 = countv.fit_transform(data['text']).toarray().tolist()\n",
    "# Results are being encoded by the 'transform' part of the method\n",
    "\n",
    "data['text'] = X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1639149018105
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   index                                              title  \\\n0      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1      1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2      2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3      3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4      4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                                text       subject  istrue  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  politicsNews       1  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  politicsNews       1  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  politicsNews       1  \n3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  politicsNews       1  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  politicsNews       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>politicsNews</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countv = CountVectorizer(max_features=5000)\n",
    "\n",
    "# max_features: we are selecting the 5000 most used words in the whole dataset\n",
    "\n",
    "X3 = countv.fit_transform(data['subject']).toarray().tolist()\n",
    "# Results are being encoded by the 'transform' part of the method\n",
    "\n",
    "data['subject'] = X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.write_feather(data, '../Data/datas.feather', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('../Data/datas.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   level_0  index                                              title  \\\n0        0      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1        1      1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2        2      2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3        3      3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4        4      4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                                text  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                       subject  istrue  \n0  [0, 0, 0, 0, 0, 0, 1, 0, 0]       1  \n1  [0, 0, 0, 0, 0, 0, 1, 0, 0]       1  \n2  [0, 0, 0, 0, 0, 0, 1, 0, 0]       1  \n3  [0, 0, 0, 0, 0, 0, 1, 0, 0]       1  \n4  [0, 0, 0, 0, 0, 0, 1, 0, 0]       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>istrue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;31mTypeError\u001B[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17620/2135793574.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mx_svm_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_svm_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_svm_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_svm_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mregr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLogisticRegression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mclassifier\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mregr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_svm_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_svm_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0my_prediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_svm_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0maccu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_svm_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_prediction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\samue\\appdata\\local\\programs\\python\\python\\310\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1506\u001B[0m             \u001B[0m_dtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1507\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1508\u001B[1;33m         X, y = self._validate_data(\n\u001B[0m\u001B[0;32m   1509\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1510\u001B[0m             \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\samue\\appdata\\local\\programs\\python\\python\\310\\venv\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    574\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    575\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 576\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    577\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    578\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\samue\\appdata\\local\\programs\\python\\python\\310\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m    954\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y cannot be None\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    955\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 956\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m    957\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    958\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\samue\\appdata\\local\\programs\\python\\python\\310\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    736\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"unsafe\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    737\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 738\u001B[1;33m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    739\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    740\u001B[0m                 raise ValueError(\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def print_accuracy(accu_r, acc) :\n",
    "    plt.plot(accu_r, acc)\n",
    "    max_accu = max(acc)\n",
    "    print(max_accu, acc.index(max_accu))\n",
    "\n",
    "\n",
    "X = data[['title', 'text', 'subject']].values\n",
    "Y = data['istrue'].values\n",
    "\n",
    "max_range = math.trunc(data.shape[0] * 0.8)\n",
    "accu_range = range(1, max_range)\n",
    "accu = []\n",
    "for val in accu_range :\n",
    "    x_svm_train, x_svm_test, y_svm_train, y_svm_test = train_test_split(X, Y, test_size=0.2, random_state=val)\n",
    "    regr = LogisticRegression(random_state=val)\n",
    "    classifier = regr.fit(x_svm_train, y_svm_train)\n",
    "    y_prediction = classifier.predict(x_svm_test)\n",
    "    accu.append(accuracy_score(y_svm_test, y_prediction))\n",
    "\n",
    "print_accuracy(accu_range, accu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}